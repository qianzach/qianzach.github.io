# Blog Post 2: IMDB Scraping!

## §1. Setup

### §1.1. Locate the Starting IMDB Page

First, pick your favorite movie/show and locate its IMDB page! Personally, my favorite show at the moment is the anime *Black Clover*, a Shonen anime.
The URL is:

https://www.imdb.com/title/tt7441658/

### §1.2. Dry-Run Navigation
Now, we’re just going to practice clicking through the navigation steps that our scraper will take.

First, click on the Cast & Crew link. This will take you to a page with URL of the form

`<original_url>fullcredits/`, or `https://www.imdb.com/title/tt7441658/fullcredits/` for me.

Next, scroll until you see the Series Cast section. Click on the portrait of one of the actors. This will take you to a page with a different-looking URL. For example, the URL for Christopher Sabat, who voices Yami Sukehiro, is

https://www.imdb.com/name/nm0754526

Finally, scroll down until you see the actor’s Filmography section. Note the titles of a few movies and TV shows in this section.

Our scraper is going to replicate this process. Starting with your favorite movie or TV show, it’s going to look at all the actors in that movie or TV show, and then log all the other movies or TV shows that they worked on.

### §1.3 Initialize Project

Create a new GitHub repository, and sync it with GitHub Desktop. This repository will house your scraper. You should commit and push each time you make significant changes to your code.
Open a terminal in the location of your repository on your laptop, and type:
```
conda activate PIC16B
scrapy startproject IMDB_scraper
cd IMDB_scraper
```

This will create quite a lot of files, but you don’t really need to touch most of them.

### §1.4 Tweak Settings
For now, add the following line to the file settings.py:

```
CLOSESPIDER_PAGECOUNT = 20
```
This line just prevents your scraper from downloading too much data while you’re still testing things out. You’ll remove this line later.

## §2. Write Your Scraper

Create a file inside the spiders directory called imdb_spider.py. Add the following lines to the file:
```
# to run 
# scrapy crawl imdb_spider -o movies.csv

import scrapy

class ImdbSpider(scrapy.Spider):
    name = 'imdb_spider'
    
    start_urls = ['https://www.imdb.com/title/tt0106145/']
```
Replace the entry of start_urls with the URL corresponding to your favorite movie or TV show.

Now, implement three parsing methods for the `ImdbSpider` class.

`parse(self, response)` should assume that you start on a movie page, and then navigate to the Cast & Crew page. Remember that this page has url `<movie_url>fullcredits`. Once there, the `parse_full_credits(self,response)` should be called, by specifying this method in the callback argument to a yielded `scrapy.Request`. The `parse()` method does not return any data. This method should be no more than 5 lines of code, excluding comments and docstrings.
`parse_full_credits(self, response)` should assume that you start on the Cast & Crew page. Its purpose is to yield a scrapy.Request for the page of each actor listed on the page. Crew members are not included. The yielded request should specify the method parse_actor_page(self, response) should be called when the actor’s page is reached. The `parse_full_credits()` method does not return any data. This method should be no more than 5 lines of code, excluding comments and docstrings.
`parse_actor_page(self, response)` should assume that you start on the page of an actor. It should yield a dictionary with two key-value pairs, of the form `{"actor" : actor_name, "movie_or_TV_name" : movie_or_TV_name}`. The method should yield one such dictionary for each of the movies or TV shows on which that actor has worked. Note that you will need to determine both the name of the actor and the name of each movie or TV show. This method should be no more than 15 lines of code, excluding comments and docstrings.
Provided that these methods are correctly implemented, you can run the command

```
scrapy crawl imdb_spider -o results.csv
```

Here's how I did it:

### `parse()`


```python
# to run 
# scrapy crawl imdb_spider -o movies.csv

import scrapy

class ImdbSpider(scrapy.Spider):
    name = 'imdb_spider'
    
    start_urls = ['https://www.imdb.com/title/tt7441658/']
    
    def parse(self, response):
        """
        the first parse() function is used to navigate and find a way to get to the Cast & Crew page
        """
        
        cast_crew = response.css("li.ipc-inline-list__item a")[2].attrib["href"]
         # If the cast and crew page exists, update the url, and move to it
        if cast_crew:
            cast_crew = response.urljoin(cast_crew) # Update url
            yield scrapy.Request(cast_crew, callback = self.parse_full_credits)
     
```

### `parse_full_credits()`

This function yields a `scrapy.Request` for the page of each actor listed on the page. In this case, we'll yield a request for every voice actor in *Black Clover*. Using Professor Chodrow's list comprehension to create a list of relative paths, we will effectively update our current URL with a new one. This will redirect us to a given voice actor's page on IMDB!


```python
       
    def parse_full_credits(self, response):
        """
        the second parse function is used within our original parse() function in the callback argument to a yielded scrapy.Request
        
        """
        paths  = [a.attrib["href"] for a in response.css("td.primary_photo a")]  #mimics process of clicking on the headshots on this page
        
        for path in paths: #iterate through the list of paths
            actor_page = "https://www.imdb.com/"  + path[1:]
            yield scrapy.Request(actor_page, callback =  self.parse_actor_page)
        
        
```

### `parse_actor_page()`

Next, we take the requests from `parse_full_credits()` and use this to get to the start of the page on a given actor. We wish to make a dictionary of the form `{"actor" : actor_name, "movie_or_TV_name" : movie_or_TV_name}` as mentioned previously in the specs. 

What we first do is extract the name of the voice actor using `response.css()`, specifically CSS selecting `"span.itemprop::text"` as our tool for this.

Then, we iterate using `response.css("div.filmo-row")` and then extract the text in `a>`, which happens to be the name of the anime/show/film. 

We slice out any trivial film names at the end to get our dictionary!


```python
    
    def parse_actor_page(self, response):
        """
        given that we are on the actor page, we want to yield a dictionary with two key-value pairs of the form:
        
        {"actor" : actor_name, "movie_or_TV_name" : movie_or_TV_name}
        
        Note that you will need to determine both the name of the actor and the name of each movie or TV show.
        
        This method should be no more than 15 lines of code, excluding comments and docstrings.
        """
        
        #first, we want to get the name
        name = response.css("span.itemprop::text").get() #extract the text in itemprop class to get name
        #https://docs.scrapy.org/en/latest/topics/selectors.html
        
        #Based on the actual list metadata, we want to iterate through the div class "filmo-category-section"
        # we want to iterate through every single film/show the given actor has been a part of
        
        for film in response.css("div.filmo-row").css("a::text"):
            film_name = film.get()
            if ("filming" and "announced" and "post-production" not in film_name) and film_name.find("Episode") == -1 and film_name.find("Show all") == -1: #get rid of trivial names
                yield {"name": name, "film/show": film_name    }
            
        
        
        
```

## §3. Scraping our IMDB Anime Data

Now, we can finally use our spider! Run the following command and we can get an output of a `.csv` file type from our resulting data!

First, comment out `CLOSESPIDER_PAGECOUNT = 20`. Then, run:

```
scrapy crawl imdb_spider -o result.csv

```

## §4. Making Recommendations Through Analysis

We wish to comptue a sorted list with the top movies and top shows that share actors with our favorite film/show. In this case, I want to do this for the anime, `Black Clover`. 

###  §4.1 Load Data


```python
import pandas as pd
import numpy as np
df = pd.read_csv("/Users/qianzach/Desktop/GitHub/IMDB_Scraper/IMDB_scraper/results1.csv")
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>film/show</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Dallas Reid</td>
      <td>SSSS.Dynazenon</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Dallas Reid</td>
      <td>What is this Entrusted Thing?</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Dallas Reid</td>
      <td>What is This Unfulfilled Wish?</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Dallas Reid</td>
      <td>What Is This Remembered Memory?</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Dallas Reid</td>
      <td>What Is This Overlapping Emotion?</td>
    </tr>
  </tbody>
</table>
</div>




```python
sorted_df = df.groupby("film/show").count().reset_index().sort_values(by="name", ascending=False)
sorted_df = sorted_df.rename(columns={"name": "actor appearances from Black Clover anime"})
sorted_df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>film/show</th>
      <th>actor appearances from Black Clover anime</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2442</th>
      <td>Black Clover</td>
      <td>361</td>
    </tr>
    <tr>
      <th>13613</th>
      <td>One Piece</td>
      <td>250</td>
    </tr>
    <tr>
      <th>5642</th>
      <td>Fairy Tail</td>
      <td>229</td>
    </tr>
    <tr>
      <th>1809</th>
      <td>Attack on Titan</td>
      <td>217</td>
    </tr>
    <tr>
      <th>14008</th>
      <td>Overlord</td>
      <td>180</td>
    </tr>
  </tbody>
</table>
</div>



We see that *Black Clover, One Piece, Fairy Tail,* and *Attack on Titan* are the most shared shows within our actors in *Black Clover*, which makes sense because many anime voice actors work in many other anime projects, especially shonen ones!

Given the prior information that a lot of the voice actors work in other anime and since I watch some of these anime, I'm not surprised. Overall, it is still extremely interesting to find this, though!
